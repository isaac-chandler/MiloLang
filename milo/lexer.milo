Token :: struct {
    using location: Source_Location
    tag: Tag
    
    using data: union {
        string_value:  string
        integer_value: u64
        float_value:   f64
    }
    
    Tag :: enum u16 {
        // Single ASCII characters represent their own tokens
        END_OF_FILE :: 128
        
        IDENTIFIER
        
        DECIMAL_LITERAL
        HEX_LITERAL
        BINARY_LITERAL
        FLOAT_LITERAL
        STRING_LITERAL
        
        NOT_EQUAL
        MOD_EQUAL
        TIMES_EQUAL
    }
}

Lexer :: struct {
    text:      string
    remaining: string
}

lex_string :: (file_uid: s32, s: string) -> (#must sucess: bool, #must tokens: [..]Token) {
    using lexer := Lexer.{file_uid = file_uid, text = s, remaining = s}
    
    tokens: [..]Token
    
    remaining = remove_hashbang(s)
    
    while true {
        success: bool
        token: Token
        
        success, token = lex_single_token(*lexer)
        
        if !sucess {
            array_free(result)
            return false, .{}
        }
        
        array_add(*tokens, token)
        
        if token == .END_OF_FILE
            break
    }
    
    return true, tokens
}

lexer_string_buffer: [..]u8

get_digit :: (character: u8, $base: u64) -> (u64, bool) {
    #if base == 10 || base == 16 {
        if '0' <= character && character <= '9' {
            return character - '0', true
        }
    }
    
    #if base == 16 {
        character_ := character & ~0x20
        
        if 'A' <= character && character <= 'F' {
            return character - 'A' + 10, true
        }
            
    }
    
    #if base == 2 {
        if character == '0' || character == '1' {
            return true, character - '0'
        }
    }

    return 0, false
}


lex_single_token :: (using lexer: *Lexer) -> (#must success: bool, #must token: Token) {
    
    remaining = remove_whitespace_and_comments(remaining)
    
    token: Token
    token.file_uid = file_uid
    token.start_offset = get_offset(<<lexer)
    
    if !remaining {
        token.end_offset = token.start_offset
        token.tag = .END_OF_FILE
        return true, token
    }
    
    maybe_equals_token :: (using lexer: *Lexer, no_equals: Token.Tag, equals: Token.Tag) -> Token.Tag {
        remaining = remaining[1..]
        if remaining && remaining[0] == '=' {
            remaining = remaining[1..]
            return equals
        } else {
            return no_equals
        }
    }
    
    maybe_equals_double_token :: (using lexer: *Lexer, no_equals: Token.Tag, equals: Token.Tag, double: Token.Tag, double_equals: Token.Tag) -> Token.Tag {
        if remaining.count >= 2 && remaining[1] == remaining[0] {
            remaining = remaining[1..]
            return maybe_equals_token(lexer, double, double_equals)
        } else {
            return maybe_equals_token(lexer, no_equals, equals)
        }
    }
    
    escape_sequence :: (using lexer: *Lexer, literal_start_offset: s32) -> (value: u32, unicode: bool, success: bool) {
        if !remaining {
            location := Source_Location.{file_uid = file_uid, start_offset = literal_start_offset, end_offset = get_offset(<<lexer)}
            report_error(location, "Found the end of file in the middle of an escape sequence")
            return 0, false, false
        }
        
        if remaining[0] == {
            case 'r'
                remaining = remaining[1..]
                return '\r', unicode = false, success = true
            case 'n'
                remaining = remaining[1..]
                return '\n', unicode = false, success = true
            case 't'
                remaining = remaining[1..]
                return '\t', unicode = false, success = true
            case 'e'
                remaining = remaining[1..]
                return '\e', unicode = false, success = true
            case '\\'
                remaining = remaining[1..]
                return '\\', unicode = false, success = true
            case '\''
                remaining = remaining[1..]
                return '\'', unicode = false, success = true
            case '"'
                remaining = remaining[1..]
                return '"', unicode = false, success = true
            case '0'
                remaining = remaining[1..]
                return 0, unicode = false, success = true
            case 'u'
                remaining = remaining[1..]
                
                if remaining.count < 6 {
                    location := Source_Location.{file_uid = file_uid, start_offset = literal_start_offset, end_offset = cast() text.count}
                    report_error(location, "Expected 6 hex digits in \\u escape")
                    return 0, false, false
                }
            
                result := 0
                        
                for 6 {
                    digit, success := get_digit(remaining[0], 16)
                    result *= 16
                    result += digit
                
                    if !success {
                        location := Source_Location.{file_uid = file_uid, start_offset = get_offset(<<lexer)}
                        location.end_offset = location.start_offset + 1
                        report_error(location, "Expected 6 hex digits in \\u escape")
                        return 0, false, false
                    }
                
                    remaining = remaining[1..]
                }
                                
                return result, unicode = true, success = true 
            case 'x'
                remaining = remaining[1..]
                
                if remaining.count < 2 {
                    location := Source_Location.{file_uid = file_uid, start_offset = literal_start_offset, end_offset = cast() text.count}
                    report_error(location, "Expected 2 hex digits in \\x escape")
                    return 0, false, false
                }
            
                result := 0
                        
                for 2 {
                    digit, success := get_digit(remaining[0], 16)
                    result *= 16
                    result += digit
                
                    if !success {
                        location := Source_Location.{file_uid = file_uid, start_offset = get_offset(<<lexer)}
                        location.end_offset = location.start_offset + 1
                        report_error(location, "Expected 2 hex digits in \\x escape")
                        return 0, false, false
                    }
                
                    remaining = remaining[1..]
                }
                                
                return result, unicode = false, success = true
            else
                location := Source_Location.{file_uid = file_uid, start_offset = get_offset(<<lexer)}
                location.end_offset = location.start_offset + 1
                report_error(location, "Invalid escape character")
                return 0, false, false
        }
    }
    
    if remaining[0] == {
        case '$' #through
        case '(' #through
        case ')' #through
        case ',' #through
        case ':' #through
        case ';' #through
        case '[' #through
        case ']' #through
        case '{' #through
        case '}' #through
        case '~'
            token.tag = cast() remaining[0]
            remaining = remaining[1..]
        case '!'
            token.tag = maybe_equals_token(lexer, cast() '!', .NOT_EQUAL)
        case '%'
            token.tag = maybe_equals_token(lexer, cast() '%', .MOD_EQUAL)
        case '*'
            token.tag = maybe_eqauls_token(lexer, cast() '*', .TIMES_EQUAL)
        case '+'
            token.tag = maybe_equals_token(lexer, cast() '+', .PLUS_EQUAL)
        case '/'
            token.tag = maybe_equals_token(lexer, cast() '/', .DIVIDE_EQUAL)
        case '='
            token.tag = maybe_equals_token(lexer, cast() '=', .EQUAL)
        case '^'
            token.tag = maybe_equals_token(lexer, cast() '^', .XOR_EQUAL)
        case '&'
            token.tag = maybe_equals_double_token(lexer, cast() '&', .BIT_AND_EQUALS, .LOGIC_AND,   .LOGIC_AND_EQUALS)
        case '|'
            token.tag = maybe_equals_double_token(lexer, cast() '|', .BIT_OR_EQUALS,  .LOGIC_OR,    .LOGIC_OR_EQUALS)
        case '<'
            token.tag = maybe_equals_double_token(lexer, cast() '<', .LESS_EQUAL,     .SHIFT_LEFT,  .SHIFT_LEFT_EQUALS)
        case '>'
            token.tag = maybe_equals_double_token(lexer, cast() '>', .GREATER_EQUAL,  .SHIFT_RIGHT, .SHIFT_RIGHT_EQUALS)
        case '-'
            remaining = remaining[1..]
            if remaining {
                if remaining[0] == {
                    case '-'
                        remaining = remaining[1..]
                        token.tag = .UNINITIALIZED
                    case '>'
                        remaining = remaining[1..]
                        token.tag = .ARROW
                    case '='
                        remaining = remaining[1..]
                        token.tag = .MINUS_EQUALS
                    else
                        token.tag = cast() '-'
                }
            } else {
                token.tag = cast() '-'
            }
        case '"'
            remaining = remaining[1..]
            
            lexer_string_buffer.count = 0
            
            while remaining {
                if remaining[0] == {
                    case '\r' #through
                    case '\n'
                        token.end_offset = get_offset(<<lexer)
                        report_error(token, "Found newline in the middle of a string literal")
                        return false, .{}
                    case '\\'
                        remaining = remaining[1..]
                        
                        if !remaining {
                            token.end_offset = get_offset(<<lexer)
                            report_error(token, "Found newline in the middle of a string literal")
                            return false, .{}
                        }
                        
                        value, unicode, success := escape_sequence(lexer)
                        
                        if !success
                            return false, .{}
                            
                        if unicode {
                            append(*lexer_string_buffer, value)
                        } else {
                            array_add(*lexer_string_buffer, cast() value)
                        }
                    case '"'
                        remaining = remaining[1..]
                        // @Improvement allow direct cast of [..]u8 to string
                        token.string_data = copy_string(cast() cast([]u8) lexer_string_buffer)
                        token.tag = .STRING_LITERAL
                        break
                    else
                        array_add(*lexer_string_buffer, remaining[0])
                        remaining = remaining[1..]
                        
                }
            } or {
                report_error("File ended in the middle of a string literal")
                return false, .{}
            }
        case '\''
            remaining = remaining[1..]
            
            if !remaining {
                
            }
            while remaining {
                if remaining[0] == {
                    case '\r' #through
                    case '\n'
                        token.end_offset = get_offset(<<lexer)
                        report_error(token, "Found newline in the middle of a string literal")
                        return false, .{}
                    case '\\'
                        remaining = remaining[1..]
                        
                        if !remaining {
                            token.end_offset = get_offset(<<lexer)
                            report_error(token, "Found newline in the middle of a string literal")
                            return false, .{}
                        }
                        
                        value, unicode, success := escape_sequence(lexer)
                        
                        if !success
                            return false, .{}
                            
                        if unicode {
                            append(*lexer_string_buffer, value)
                        } else {
                            array_add(*lexer_string_buffer, cast() value)
                        }
                    case '"'
                        remaining = remaining[1..]
                        // @Improvement allow direct cast of [..]u8 to string
                        token.string_data = copy_string(cast() cast([]u8) lexer_string_buffer)
                        token.tag = .STRING_LITERAL
                        break
                    else
                        array_add(*lexer_string_buffer, remaining[0])
                        remaining = remaining[1..]
                        
                }
            } or {
                report_error("File ended in the middle of a string literal")
                return false, .{}
            }
        case '0'
            
        case '1' #through
        case '2' #through
        case '3' #through
        case '4' #through
        case '5' #through
        case '6' #through
        case '7' #through
        case '8' #through
        case '9'
            
        case '#'
        case 'A' #through 
        case 'B' #through
        case 'C' #through
        case 'D' #through
        case 'E' #through
        case 'F' #through
        case 'G' #through
        case 'H' #through
        case 'I' #through
        case 'J' #through
        case 'K' #through
        case 'L' #through
        case 'M' #through
        case 'N' #through
        case 'O' #through
        case 'P' #through
        case 'Q' #through
        case 'R' #through
        case 'S' #through
        case 'T' #through
        case 'U' #through
        case 'V' #through
        case 'W' #through
        case 'X' #through
        case 'Y' #through
        case 'Z' #through
        case '_' #through
        case 'a' #through
        case 'b' #through
        case 'c' #through
        case 'd' #through
        case 'e' #through
        case 'f' #through
        case 'g' #through
        case 'h' #through
        case 'i' #through
        case 'j' #through
        case 'k' #through
        case 'l' #through
        case 'm' #through
        case 'n' #through
        case 'o' #through
        case 'p' #through
        case 'q' #through
        case 'r' #through
        case 's' #through
        case 't' #through
        case 'u' #through
        case 'v' #through
        case 'w' #through
        case 'x' #through
        case 'y' #through
        case 'z'
            
    }
    
    token.end = get_offset(<<lexer)
    
    return true, token
}

get_offset :: (using lexer: Lexer) {
    if remaining {
        return cast() (remaining.data - text.data)
    } else {
        return cast() text.count
    }
}

remove_hashbang :: (s: string) -> string {
    if s.count < 2 || s[0..2] != "#!" {
        return s
    }
    
    remaining := s[2..]
    
    
    
    return remaining
}

remove_whitespace_and_comments :: (s: string) -> string {
    remaining := s
    
    while remaining {
        if remaining[0] == {
            case '\t' #through
            case '\r' #through
            case '\n' #through
            case ' ' 
                remaining = remaining[1..]
            case '/'
                if remaining.count < 2
                    break
                    
                if remaining[1] == '/' {
                    remaining = remove_line(remaining[2..])
                } else if remaining[1] == '*' {
                    remaining = remaining
                    
                    block_comment_count := 1
                    
                    while remaining {
                        if remaining.count < 2 {
                            remaining = ""
                            break
                        }
                        
                        if remaining[0..1] == "/*" {
                            block_comment_count += 1
                            remaining = remaining[2..]
                        } else if remaining[0..1] == "*/" {
                            block_comment_count -= 1
                            remaining = remaining[2..]
                            if !block_comment_count
                                break
                        } else {
                            remaining = remaining[1..]
                        }
                    }
                } else {
                    break
                }
            else 
                break
        }
    }
    
    return remaining
}

remove_line :: (s: string) -> string {
    remaining := s
    
    while remaining {
        if remaining[0] == '\r' {
            remaining = remaining[1..]
            if remaining && remaining[0] == '\n'
                remaining = remaining[1..]
            break
        } else if remaining[0] == '\n' {
            remaining = remaining[1..]
            break
        }
    }
    
    return remaining
}